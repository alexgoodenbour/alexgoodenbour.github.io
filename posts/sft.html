<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2023-10-28 Sat 21:14 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Part III Notes: Statistical Field Theory</title>
<meta name="author" content="Alex Goodenbour" />
<meta name="generator" content="Org Mode" />
<link rel="stylesheet" href="/res/main.css" type="text/css"/>
<script>
  window.MathJax = {
    tex: {
      ams: {
        multlineWidth: '85%'
      },
      tags: 'ams',
      tagSide: 'right',
      tagIndent: '.8em'
    },
    chtml: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    svg: {
      scale: 1.0,
      displayAlign: 'center',
      displayIndent: '0em'
    },
    output: {
      font: 'mathjax-modern',
      displayOverflow: 'overflow'
    }
  };
</script>

<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
<div id="preamble" class="status">
<header class="header">
<h3> <a id="header-title" href="/">The Aleph</a></h3>
  <nav>
      <a href="/about" target="">About</a>
      <a href="/" target="">Home</a>
      <!-- <a href="/posts" target="">Posts</a> -->
  </nav>
</header>
<hr style="color: grey">
<p class='date'>November 1, 2023</p>
</div>
<div id="content" class="content">
<h1 class="title">Part III Notes: Statistical Field Theory</h1>
<p>
Closely follows David Tong's lecture notes.
</p>

<div id="outline-container-org1a73011" class="outline-2">
<h2 id="org1a73011">Notes</h2>
<div class="outline-text-2" id="text-org1a73011">
</div>
<div id="outline-container-org9bafada" class="outline-3">
<h3 id="org9bafada">Preliminaries</h3>
<div class="outline-text-3" id="text-org9bafada">
<p>
The content in this section does not derive from lecture material.
</p>
</div>

<div id="outline-container-orgabb80d1" class="outline-4">
<h4 id="orgabb80d1"><span class="todo TODO">TODO</span> Statistical mechanics</h4>
<div class="outline-text-4" id="text-orgabb80d1">
</div>
<div id="outline-container-org7f728e4" class="outline-5">
<h5 id="org7f728e4"><span class="todo TODO">TODO</span> Partition functions</h5>
<div class="outline-text-5" id="text-org7f728e4">
<p>
&#x2026; and their relationship to free energy
</p>
</div>
</div>

<div id="outline-container-orgfbdafa7" class="outline-5">
<h5 id="orgfbdafa7">Legendre transforms</h5>
<div class="outline-text-5" id="text-orgfbdafa7">
<p>
&#x2026; relationship between thermodynamic quantities.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org9b374ac" class="outline-3">
<h3 id="org9b374ac">Motivation</h3>
<div class="outline-text-3" id="text-org9b374ac">
<p>
A major focus of the course will be phase transitions of physical
systems. These exhibit <i>discontinuous</i> or abrupt behaviour. This is
because they are <i>emergent</i> behaviour.
</p>

<p>
We will be especially interested in <b>second-order</b> phase transitions
i.e. critical points.
</p>

<p>
e.g. the heat capacity of water changes with temperature as 
</p>
\begin{equation}
\label{eq:1}
C \approx \frac{1}{|T-T_c|^{0.11008..}}
\end{equation}
<p>
It turns out that although the critical temperature changes with the
liquid under consideration, the exponent is <i>universal</i>.
</p>

<p>
This notion of universality of phenomena is very important in
statistical physics. One example that we will soon come across is the
use of symmetry to talk about states of matter (due to Landau).
</p>

<p>
Statistical physics is also self-conscious of exactly how much it can
say about a physical system. We will study the way that physics at one
length scfale affects the physics at other scales. The formal
apparatus for studying this is the <i>renormalisation group</i> (due to Ken
Wilson).
</p>
</div>
</div>

<div id="outline-container-org7a9c0a4" class="outline-3">
<h3 id="org7a9c0a4">1 - From Spins to Fields</h3>
<div class="outline-text-3" id="text-org7a9c0a4">
<div class="mdframed" id="org590394d">
<p>
In which we consider the calculation of the partition function of the
Ising model in the large \(N\) limit through various layers of
approximation to introduce the emergence of <i>fields</i> in statistical
mechanics.
</p>

<p>
In each case, our goal is to calculate the partition function which is
a sum over configurations weighted by the energy assigned to that
configuration. We consider successively large <i>partitions</i> of the
sum. First in the <i>mean field approximation</i> where we lump together
configurations by <i>average spin</i>, and next where spin is averaged
<i>locally</i> so that there is a whole <i>function</i> assigned to each
configuration.
</p>

<p>
In both cases, we consider what the approximation tells us about the
behaviour of macroscopic variables close to <i>critical
points</i>. This is called <i>Laundau theory</i> in MFT and <i>Laundau-Ginzberg
theory</i> for the locally-averaged case.
</p>

</div>
</div>

<div id="outline-container-org50aee77" class="outline-4">
<h4 id="org50aee77">The Ising Model</h4>
<div class="outline-text-4" id="text-org50aee77">
<p>
Simple model of a magnet. Lattice in \(d\) spatial dimensions with \(N\)
nodes. On each node \(i = 1..N\) is a discrete variable which takes
values \(\pm 1\). Call it spin (arb. label). \(S_i = \pm 1\).
</p>

<p>
System of spins \(\{S_i\}\) has energy
</p>
\begin{equation}
\label{eq:2}
E = -B \sum_i S_i - J \sum_{<ij>} S_i S_j
\end{equation}
<p>
where the sum over \(<ij>\) means sum over pairs of nearest neighbours
(up down left right but not diagonal). w/ \(B\) an external magnetic
field.
</p>

<p>

</p>

<p>
Minimising energy means:
\(B>0\) prefers spin up 
\(B<0\) prefers spin down
\(J>0\) prefers spin-aligned (ferromagnetic)
\(J<0\) prefers anti-aligned
</p>

<p>
"There is a tension between minimising energy and increasing entropy"
</p>

<p>
We'll always take \(J>0\). A finite temperature \(T\) means that spins
want to randomise to increase entropy.
</p>

<p>
In the canonical ensemble (contact with heat bath of constant temp
\(T\)), the probability of a configuration \({S_i}\) is
</p>
\begin{equation}
\label{eq:3}
P[S_i] = e^{-\beta E[S_i]}/Z
\end{equation}
<p>
where \(Z(T,J,B) = \sum_{{S_i}} e^{-\beta E[S_i]}\).
</p>

<p>
<b>Note:</b> \(P[S_i]\) is a number assigned to a single configuration,
 \(Z\) is a quantity which sums over all possible configurations (for
 given macroscopic parameters \(T,J,B\)). Note also that \(\beta =
 1/T\). 
</p>

<p>
"All physics can be extracted from \(Z\)" e.g. \(\left< E \right> =
-\frac{\partial}{\partial \beta} \ln Z\).
</p>

<p>
Now we define a couple quantities.
</p>

<p>
Thinking of thermodynamic free energies, the Helmholtz free energy is
relevant here because we have a fixed volume (lattice). Remember,
</p>
\begin{equation}
\label{eq:4}
F_{\text{thermo}}(T,J,B) = \left< E \right> - TS = -T \ln Z
\end{equation}

<p>
(Note then \(Z = e^{-\beta F_{\text{thermo}}}\) and so there is a
sense in which \(Z\) and \(F_{\text{thermo}}\) provide the same
information. Identify them in your head. We will end up with an
expression for \(F_{\text{thermo}}\). This is as good as if we have
the partition function.
</p>

<p>
<b>Question:</b> The relationship between free energies (revising thermo,
Legendre transform)
</p>

<div class="mdframed" id="orga4e8a84">
<p>
<b>Legendre transforms</b>
</p>

<p>
&#x2026;
</p>

</div>

<p>
Also define a quantity, the <i>equilibrium magnetisation</i>
</p>
\begin{equation}
\label{eq:5}
m_{\text{equ}} = \frac{1}{N}  \left< \sum_i S_i \right> \in [-1,1]
\end{equation}
<p>
i.e. the expected value (over configurations) of the average spin.
</p>

<p>
<b>Note:</b> \(m_{\text{equ}}\) is a single number that depends only on the macroscopic
parameters. i.e. it is not specific to a single configuration due to
the average over configurations.
</p>

<p>
The average operation there is defined as
</p>
\begin{equation}
\label{eq:9}
\left< X \right> = \sum \frac{X_n e^{-\beta E_n}}{Z}
\end{equation}
<p>
i.e. a weighted sum over the values in each microstate.
</p>

<p>
So that, \(m\) can be expressed
</p>
\begin{equation}
\label{eq:6}
m_{\text{equ}} = \frac{1}{N} \sum_{{S_i}} \frac{e^{-\beta E[S_i]}}{Z} \sum_i S_i = \frac{1}{N\beta} \frac{\partial \ln Z}{\partial B}
\end{equation}

<p>
Now, we want to understand how this changes with \(T\) and \(B\). In
fact, all we need is \(Z\) but we will compute it indirectly.
</p>

<p>
<i>"Our objective is to understand the quantity \(m_{\text{equ}}\). It is
understood that it has some predetermined physical relevance. In fact,
the partition function contains all the information we need so we will
try to compute the partition function."</i>
</p>

<p>
It is not possible in general to do the sum to compute the partition
function.
</p>

<p>
<b>Note:</b> The Ising model is like a puppet without a hand. Specification
 of ensemble is a chosen distribution of configurations wrt energy.
</p>

<p>
<b>Effective free energy</b> (a quantity inbetween scales of information)
It is more fine grained that \(F_{\text{thermo}}\) but does not
contain all the information about a configuration.
</p>

<p>
Rewrite \(Z\) as 
</p>
\begin{equation}
\label{eq:7}
Z = \sum_m \sum_{{S_i}|m} e^{-\beta E[S_i]} := \sum_m e^{-\beta F(m)}
\end{equation}
<p>
so we just split the sum into parts of constant \(m\) but with \(m = \frac{1}{N} \sum_i S_i\). 
above. This is a different quantity to the previous \(m\) which was a
number assigned to the entire ensemble of configurations whereas this
\(m\) is just the average magnetisation of a single configuration.
</p>

<p>
We will define a quantity \(F(m)\) so that the second equality
holds.
</p>

<p>
We now introduce the large \(N\) limit so that we have an integral.
</p>
\begin{equation}
\label{eq:8}
Z = \frac{N}{2} \int_{-1}^1 dm\ e^{-\beta F(m)}
\end{equation}
<p>
where the prefactor comes about because if one spin flips, this will
change \(m\) by \(2/N\) therefore the above is the natural measure for
integration.
</p>

<p>
Note \(F = F(m,\beta,J,B)\) and \(F_{\text{thermo}} = F_{\text{thermo}}(\beta,J,B)\).
</p>

<p>
"Effective free energy carries more information than Helmholtz. It is
intermediate between the micro and macroscopic descriptions."
</p>

<p>
<b>Note:</b> Furthermore, \(F_{\text{thermo}}\) is an equilibrium
quantity. An average is taken over all configurations. \(F(m)\) on the
other hand is not an equilibrium quantity for a given \(m\) since we
have defined a quantity on an arbitrary slice of the distribution.
</p>

<p>
We can extract the equilibrium value of \(m\) from \(F\). First we
define a rescaled quantity \(f(m) := F(m)/N\) (it will help with large
\(N\) limit). Then
</p>
\begin{equation}
\label{eq:8}
Z = \frac{N}{2} \int_{-1}^1 dm\ e^{-\beta Nf(m)}
\end{equation}

<p>
Saddle-point/steepest descent method says that for large \(N\), this
integral is approximated well by the value  of \(m\) for which
\(f(m)\) is minimised.
</p>
\begin{equation}
\label{eq:10}
\left. \frac{df}{dm} \right|_{m=m_{\text{min}}} = 0
\end{equation}
<p>
So that \(Z \approx e^{-\beta N f(m_{\text{min}})}\). Therefore in
fact,
</p>
\begin{equation}
\label{eq:11}
F_{\text{thermo}} = -T \ln Z \approx F(m_{\text{min}})
\end{equation}
<p>
So that for this minimising value of \(m\), the effective free energy
is Helmholtz.
</p>

<p>
Knowing that \(F_{\text{thermo}}\) is just a re-expressed partition
function, we can compute the partition function by knowing about this
<i>intermediate</i> function \(F(m)\). We will proceed by a guess: <i>mean
field theory</i>.
</p>

<p>
<b>Question:</b> Why is \(F(m)\) easier to determine than the partition
function itself? Perhaps because we can count the states quite easily.
</p>
</div>

<div id="outline-container-org3c3158b" class="outline-5">
<h5 id="org3c3158b">Mean field theory</h5>
<div class="outline-text-5" id="text-org3c3158b">
<p>
To proceed we make an assumption. We will say that we don't care about
the small interactions and micro information. We will assume that it
is as if each spin has the value of the average spin.
</p>
\begin{equation}
\label{eq:13}
s_i = \sum_i s_i /N \equiv m
\end{equation}

<p>
Then the energy becomes (after a second of thought)
</p>
\begin{equation}
\label{eq:14}
E = -B \sum_i m - J \sum_{<ij>} m^2 = -BNm - \frac12 J q m^2
\end{equation}
<p>
where \(q\) is the number of nearest neighbours.
</p>

<p>
Note that this is a very odd thing to do since each \(s_i\) is
discrete but we are assuming it takes on a continuous value. Also we
erase any fine grained detail. But doing so makes summing over
configurations very easy.
</p>

<p>
Because we still need to arrive at the value of \(m\) by a number of
up and down \(s_i\), we must have \(m = \frac{N_{\uparrow}-
N_{\downarrow}}{N} = \frac{2 N_{\uparrow}-N}{N}\) since
\(N_{\uparrow}+N_{\downarrow} = N\).
</p>

<p>
The number of configurations with so many up and down configurations
is
</p>
\begin{equation}
\label{eq:15}
\Omega = \frac{N!}{N_{\uparrow}!(N-N_{\uparrow})!}
\end{equation}
<p>
(The intuition here is that you imagine you have \(N\) objects to
arrange in a line like "abcdef&#x2026;". There are \(N!\) ways to arrange
so many objects. But if <i>up</i> and <i>down</i> spins are identified you need
to mod them out. Therefore divide by \(N_{\uparrow}!\) and
\(N_{\downarrow}!\) and that's it.)
</p>

<p>
<b>Stirling's formula:</b> For large \(n\), \(\ln(n!) = n\lnn - n +
 \mathcal{O}(\ln n)\).
</p>

<p>
Apply to the above expression for \(\Omega\), eliminate
\(N_{\uparrow}\) in favour of \(m\) by the above expression so that we
have a count of the number of configurations with a given \(m\).
</p>

<p>
Now, we are trying to compute \(F(m)\) (or \(f(m)\)) which was
implicitly defined according to 
</p>
\begin{equation}
\label{eq:7}
Z = \sum_m \sum_{{S_i}|m} e^{-\beta E[S_i]} := \sum_m e^{-\beta F(m)}
\end{equation}
<p>
Now we can compute the second sum (for constant \(m\)) because the
expression summed over is just energy (and macro vars) which only
depends on \(m\) which will be constant in the sum. Therefore the sum
is trivial and just picks up a factor: the number of configurations
with that value of \(m\): \(\Omega(m)\).
</p>

<p>
This means
</p>
\begin{equation}
\label{eq:16}
e^{-\beta N f(m)} = \Omega(m) e^{-\beta E(m)}
\end{equation}
<p>
and since we have expressions for \(\Omega(m)\) and \(E(m)\) now, we
have \(f(m)\) explicitly (in the large \(N\) limit in the mean field
approximation).
</p>
\begin{equation}
\label{eq:12}
f(m) \approx -Bm - \frac12 J qm^2 -T \left( \log 2 - \frac12 (1+m) \log(1+m) - \frac12 (1-m) \log(1-m) \right)
\end{equation}

<p>
Great. Now we remember that the value of \(m\) that minimises \(f(m)\)
is the equilibrium magnetisation and the corresponding \(F(m)\) is
\(F_{\text{thermo}}\) and so we would have the partition function too.
</p>

<p>
The condition \(\frac{\partial f}{\partial m} = 0\) gives (with some
algebra),
</p>
\begin{equation}
\label{eq:17}
m = \tanh \left( \beta B + \beta J q m \right)
\end{equation}

<p>
Very nice. This can also be arrived at by assuming that the
coefficient of \(\beta\) under there is an <i>effective</i> magnetic field
called the <i>mean field</i> hence the name.
</p>
</div>
</div>

<div id="outline-container-orgd4e7ba3" class="outline-5">
<h5 id="orgd4e7ba3">Laundau approach to phase transitions</h5>
<div class="outline-text-5" id="text-orgd4e7ba3">
<div class="mdframed" id="orge45d56e">
<p>
In which we take our partition function which has been reduced to a
sum over the macroscopic quantity \(m\) and can be approximated by the
term in the sum corresponding to the minimising value of \(m\), and consider
how certain quantities change as we approach critical points.
</p>

</div>

<p>
A phase transition occurs when some quantity changes
discontinuously/abruptly.
</p>

<p>
For our example the quantity or <i>order parameter</i> is
\(m_{\text{min}}\).
</p>

<p>
Let us Taylor expand our nice expression for \(f(m)\) from the
previous section for small \(m\).
</p>
\begin{equation}
\label{eq:18}
f(m) \approx -\frac1{\beta} \ln 2 - Bm + \frac12 \left( T - Jq \right)m^2 + \frac{1}{12} Tm^4 + ...
\end{equation}
<p>
where the first term isn't of much use. The minimising value of \(m\)
is what we really care about, so we are interested in how the minimum
of this function changes as we vary the system parameters.
</p>

<p>
<i>The next while will just be analysing this function</i>
</p>

<p>
<b>Consider first the case \(B = 0\):</b>
</p>

<p>
We have

</p>

<p>
So that we have a bifurcation in the minimum. So on one side, \(m =
0\), and
 on the other \(m = \pm \sqrt{\frac{3 \left( T_c - T \right)
}{T}}\). Obviously the bifurcation happens at \(T_c = Jq\).
</p>

<p>
Note that this only works for small \(m\) and so based on a further
piece of information, namely that the two forks of the bifurcation
should tend to \(\pm 1\) for low temperatures (i.e. alignment wins out
over entropy) we can draw a global bifurcation diagram.
</p>

<p>

</p>

<p>
When we are on the \(m=0\) side i.e. above the critical temperature,
we say the system sits in <i>disordered phase</i>. The other side is the
<i>ordered phase</i>.
</p>

<p>
Note that although abrupt, the transition is continuous so that this
is a <i>continuous</i> or sometimes <i>second order</i> phase transition.
</p>

<p>
<b>Note:</b> \(f(m)\) is invariant under \(\mathbb{Z}_2\) \(m \to -m\)
inherited from the \(s_i \to -s_i\) symmetry of the \(B = 0\) Ising
model.
</p>

<p>
<b>Aside:</b> Phase transitions can be classified by looking at the
thermodynamic free energy \(F_{\text{thermo}}\) (or the partition
function) and taking derivatives wrt thermodynamic (macroscopic)
variables. If the discontinuity shows up at the \(n^{\text{th}}\)
derivative then we give it the name \(n^{\text{th}}\) order phase
transition. Our next example of this will be heat capacity.
</p>

<p>
<b>Note:</b> \(Z\) is made up of analytic functions but loses analyticity
in the large \(N\) limit hence how it can be possible to have
discontinuities in derivatives.
</p>

<p>
<b>Heat capacity (for later)</b>
</p>
\begin{equation}
\label{eq:19}
C = \frac{\partial \left< E \right>}{\partial T} = \beta^2 \frac{\partial^2}{\delta \beta^2} \log Z
\end{equation}
<p>
in the canonical ensemble. Since we have \(Z\) via
\(F_{\text{thermo}}\) from \(F(m_{\text{min}})\), we can quite easily
express this as a function of \(m\). \(Z \approx e^{-\beta N f(m_{\text{min}})}\)
</p>

<p>
Then just pull values of \(f(m_{\text{min}})\) from the analysis
above. Find \(c = \frac{C}{N}\) is either \(0\) or \(3/2\) depending
on which side we approach the critical temperature from.
</p>

<p>
"Strictly speaking, spontaneous symmetry breaking can only occur in
infinite systems." 
</p>

<p>
<b>\(B \neq 0\): First order phase transition</b>
</p>

<p>
Somewhat expectedly, this breaks the symmetry we had in the previous
case.
</p>

<p>

At low temperatures, two minima. One more stable than another. The
less stable one is called <i>meta-stable</i>: by fluctuating up over the
barrier it can become more stable.
</p>

<p>
The most important thing is that the ground state of the system does
not qualitatively change as we vary the temperature.
</p>

<p>

</p>

<p>
<i>"There is no phase transition as a function of the temperature for \(B
\neq 0\)"</i>
</p>

<p>
But we don't have to look hard to find a phase transition: we just
need to move along a different path in the phase diagram.
</p>

<p>
That path is: <b>keep \(T\) fixed and vary \(B\) above and below 0</b>.
</p>

<p>
The stable and meta-stable states swap essentially. But there are only
two states below the critical temperature so this phase transition
only happens for \(B = 0,\ T<T_c\).

So <i>the line of first order phase transitions ends in a second order
phase transition at \(T = T_c\).</i> Weirdly though, we can just go around
it to access all parts of the phase diagram.
</p>
</div>

<ul class="org-ul">
<li><a id="org31f536d"></a>Close to the critical point<br />
<div class="outline-text-6" id="text-org31f536d">
<p>
"It will prove interesting to explore what happens when we sit close
to the critical temperature." 
</p>

<p>
<b>How does the (equ) magnetisation change with \(B\)?</b> Well we have
</p>
\begin{equation}
\label{eq:20}
f(m) \approx -B m + \frac{1}{12} T_c m^4
\end{equation}
<p>
so that minimising gives \(m \sim B^{1/3}\).
</p>

<p>
<b>How does the magnetic susceptibility change with \(T\)?</b> Define
</p>
\begin{equation}
\label{eq:21}
\chi = \left. \frac{\partial m}{\partial B} \right|_T
\end{equation}
<p>
For \(T>T_c\), \(f(m) \approx -Bm + \frac12 \left( T - T_c \right) m^2\) so that
minimising gives 
</p>
\begin{equation}
\label{eq:22}
\chi \sim \frac{1}{T - T_c}
\end{equation}
</div>
</li>
</ul>
</div>
<div id="outline-container-org783274e" class="outline-5">
<h5 id="org783274e">Validity of mean field theory</h5>
<div class="outline-text-5" id="text-org783274e">
<p>
The following are some facts. We will justify the facts in lectures to
come.
</p>
<ul class="org-ul">
<li>In \(d=1\) MFT fails completely. There are no phase transitions</li>
<li>In \(d=2,3\) the basic structure of the phase diagram is correct but
detailed predictions at \(T \approx T_c\) are wrong</li>
<li>In \(d \geq 4\) MFT gives the right answers</li>
</ul>

<p>
This basic pattern will hold for other models as well. MFT always
fails for \(d \leq d_l\) the <i>lower critical dimension</i> and always
works above some dimension, the <i>upper critical dimension</i>. The
in-between cases are often interesting.
</p>

<p>
In the Ising model, roughly, MFT works because as \(d\) increases,
each node has more neighbours and so the net effect experienced is
closer to the average.
</p>
</div>
<ul class="org-ul">
<li><a id="org2f56b29"></a>Critical exponents<br />
<div class="outline-text-6" id="text-org2f56b29">
<p>
In the intermediate dimensions, the crude structure of the phase
diagram from MFT may be correct but it gives misleading results near
the critical point.
</p>

<p>
It is the exponents we found which will vary between MFT and the true
behaviour of the Ising model. In fact the correct values are not
integers or simple fractions and would appear to be irrational.
</p>
</div>
</li>
</ul>
</div>
<div id="outline-container-orge7be836" class="outline-5">
<h5 id="orge7be836">Universality</h5>
<div class="outline-text-5" id="text-orge7be836">
<p>
Liquid-gas transitions show many similarities to the Ising model.

</p>

<p>
We have a line of first order phase transitions which end in a
critical point. The order parameter is the volume per particle
instead. Perhaps we use some equation of state e.g. Van der Waals at
critical point.
</p>

<p>
Unfortunately none of the critical exponents one calculates agree with
experiment. In fact, the true values match the true values of the
Ising model.
</p>

<p>
"Universality: same critical point governs beahviour of many different
physical systems. Why?"
</p>

<p>
<b>Note:</b> in the lecture notes there is a discussion of the formal
similarities between the Ising model and a lattice gas model of
liquid-gas transitions.
</p>
</div>
</div>
</div>
<div id="outline-container-orgdf3cef1" class="outline-4">
<h4 id="orgdf3cef1">Landau-Ginzburg theory</h4>
<div class="outline-text-4" id="text-orgdf3cef1">
<div class="mdframed" id="org874c9e2">
<p>
In which we consider assigning a whole function to each configuration
instead of just a number. We average <i>locally</i> and partition the sum
over configurations according the the value of that function for each
configuration.
</p>

<p>
We find that allowing the "spin to vary spatially", there are certain
<i>fluctuations</i> which affect the values of the <i>critical exponents</i>
defined in the previous chapter. By fluctuations here, we mean sets of
configurations within the configuration space which contribute in an
outsized way to the partition function.
</p>

<p>
Functionals come about since we are summing over function spaces now.
</p>

</div>

<p>
Treated correctly, this will give the right physics.
</p>

<p>
"Laundau theory is too coarse. No spatial variations, just one number
\(m\) assigned to a configuration."
</p>

<p>
So, we allow \(m\) to vary in space. \(m \to m(x))\). We start with
\(N\) sites, divide into boxes each with \(N'\) sites with \(1 \ll N'
\ll N\).
</p>

<p>
For each box, take the average spin and assign it to some point within
the box (centre, corner, doesn't matter)
</p>
\begin{equation}
\label{eq:23}
m(x) = \frac{1}{N'} \sum_i s_i
\end{equation}
<p>
where the sum is over sites in the box. Now, if we have a really large
\(N'\) and a much much larger \(N\), then this can be taken to be a
field on spacetime. We must only keep in mind that \(m\) can't vary on
scales smaller than the box size.
</p>

<p>
Just like previous analyses, write the partition function as a split
sum over all states with a given \(m(x)\) and then a sum over
individual configurations within that subset. Then define a quantity
analogous to the effective free energy.
</p>
\begin{equation}
\label{eq:24}
Z = \sum_{m(x)} \sum_{{s_i}|m(x)} e^{-\beta E[s_i]} := \sum_{m(x)} e^{-\beta F[m(x)]}
\end{equation}
<p>
Note that the quantity \(F[m(x)]\) is a functional called the
<i>Laundau-Ginzburg free energy</i> and in fact our sum
over \(m(x)\) is a path integral!
</p>
\begin{equation}
\label{eq:25}
Z = \int \mathcal{D} m(x) e^{-\beta F[m(x)]}
\end{equation}
<p>
and the probability (density?) of a configuration having a given
\(m(x)\) is
</p>
\begin{equation}
\label{eq:26}
p[m(x)] = \frac{e^{-\beta F[m(x)]}}{Z}
\end{equation}

<p>
Note that there is something dodgy about this box construction so we
should be careful.
</p>

<p>
"Now we're doing field theory."
</p>
</div>
<div id="outline-container-orgbb32b96" class="outline-5">
<h5 id="orgbb32b96">Laundau-Ginzburg free energy</h5>
<div class="outline-text-5" id="text-orgbb32b96">
<p>
What is the free energy functional defined above? What can is possibly
be? Like in mean field theory, our objective is to calculate this
quantity because at the minimising \(m(x)\) it gives us our partition
function among other reasons.
</p>

<p>
It must have the following properties:
</p>
<ul class="org-ul">
<li>Locality: In the Ising model spins only affect neighbours
<ul class="org-ul">
<li>Therefore we should be able to write it as an integral, as we can
for an action functional</li>
</ul></li>
</ul>
\begin{equation}
\label{eq:27}
F[m(x)] = \int d^d x f[m(x)]
\end{equation}
<p>
Note that \(f[m(x)]\) may depend on \(m(x)\) and its derivatives.
</p>
<ul class="org-ul">
<li>Translation and rotation invariance: inherited from discrete
versions. Perhaps some thought required for how rotational
symmetries are inherited from a lattice.</li>
<li>\(Z_2\) symmetry: When \(B = 0\), the original Ising model is invariant under \(s_i
  \to -s_i\) on all sites. Therefore in our coarse-grained theory we
should have</li>
</ul>
\begin{equation}
\label{eq:28}
m(x) \rightarrow -m(x)
\end{equation}
<p>
Without the condition that \(B = 0\), the Ising model is still
invariant under \(m(x) \rightarrow -m(x)\) together with \(B
\rightarrow -B\).
</p>
<ul class="org-ul">
<li>Analyticity: We are interested in critical point where \(m\) is
small. We would like a taylor expansion of \(f[m(x)]\).
<ul class="org-ul">
<li>Furthermore, we will only consider cases when \(m(x)\) varies
rather slowly in space. We will assume that \(m(x)\) varies
appreciably only over distances taht are much larger than the
distance between boxes.</li>
</ul></li>
</ul>

<p>
With these conditions in mind, we write down the most general form for
\(F[m(x)]\) first when \(B = 0\):
</p>
\begin{equation}
\label{eq:29}
F[m(x)] = \int d^d x \left[ \frac12 \alpha_2(T) m^2 + \frac14 \alpha_4(T) m^4 + \frac12 \gamma(T) (\nabla m)^2 + ... \right]
\end{equation}
<p>
Note that we are ignoring a constant wrt \(m\) term like last time,
and we have no terms linear in the gradient so that we don't violate
rotational symmetry, and the linear and cubic terms in \(m\) are
missing since they don't respect the \(Z_2\) symmetry.
</p>

<p>
Notice how similar this is to constructing an action in field
theory. Note that the action is a number assigned to a field
configuration throughout spacetime, and this functional is a number
applied to some configuration (based on the \(m(x)\) of that
configuration) with no notion of evolving over time.
</p>

<p>
When \(B \neq 0\) we can have terms that combine \(B\) and \(m\) to
respect the \(Z_2\) symmetry e.g. \(Bm, Bm^3\) etc.
</p>

<p>
"Turns out to be hard to compute the coefficients \(\alpha_n(T)\)."
</p>

<p>
These are going to be quantities related to the physical system. We
could take the values from MFT theory if we like by plugging in only
constant functions \(m(x) = m\) and comparing with the MFT
expression. We don't need to do this though, we'll just leave these
coefficients undetermined. We will note that \(\alpha_4(T) > 0,\
\gamma(T) > 0\), while \(\alpha_2(T)\) flips sign at the second order
phase transition.
</p>

<p>
Peek ahead: This prescription does give the right results but that
path integral is really hard to do.
</p>
</div>
</div>

<div id="outline-container-orgf7cca0f" class="outline-5">
<h5 id="orgf7cca0f">Saddle point and domain walls</h5>
<div class="outline-text-5" id="text-orgf7cca0f">
<p>
Before we try to compute the path integral, we'll try to resort to the
saddle point method, <i>assume the path integral is dominated by the
configurations that minimise \(F[m(x)]\).</i>
</p>

<p>
Compute \(\delta F\) the normal way, get rid of the \(\nabla \delta
m\) by integrating by parts and dismissing the surface term.
</p>
\begin{align*}
\delta F &= \int d^d x \left[ \alpha_2(T) m + \alpha_4(T) m^3 - \gamma \nabla^2 m \right] \delta m \\
&\equiv \int d^d x \frac{\delta F}{\delta m(x)} \delta m
\end{align*}
<p>
where we have defined the notion of a <i>functional derivative</i>. Note
that because it's under the integral, it's a function of \(x\). We
have
</p>
\begin{equation}
\label{eq:30}
\frac{\delta F}{\delta m(x)} = \alpha_2 m(x) + \alpha_4 m^3(x) - \gamma \nabla^2 m(x)
\end{equation}
<p>
The configuration \(m(x)\) which makes this 0 is the solution to the
Euler-Lagrange equations. Write
</p>
\begin{equation}
\label{eq:31}
\left. \frac{\delta F}{\delta m} \right|_{m(x)}=0\ \implies \gamma \nabla^2 m = \alpha_2 m + \alpha_4 m^3
\end{equation}
<p>
The simplest solutions to this DE are constant. We find the two
situations:
</p>
<ul class="org-ul">
<li>\(T > T_c\) gives \(m=0\)</li>
<li>\(T < T_c\) \(m = \pm m_0\)</li>
</ul>
<p>
just like Laundau/MF theory. So in that sense, MFT is the saddle-point
approximation of this new prescription. Although we will see that more
than just a constant \(m(x)\) will be permitted.
</p>
</div>

<ul class="org-ul">
<li><a id="org8941b6f"></a>Domain walls<br />
<div class="outline-text-6" id="text-org8941b6f">
<p>
Take \(T < T_c\) so we have the two degenerate ground states \(m = \pm
m_0\). Let us consider some kind of configuration where we have
spatial interpolation between these two states and consider whether
there is a solution to the above PDE that works.
</p>

<p>
We can reduce the problem to one spatial dimension since the field
need only change in one direction in which case we have an ODE 
</p>
\begin{equation}
\label{eq:32}
\gamma \frac{d^2 m}{dx^2} = \alpha_2 m + \alpha_4 m^3
\end{equation}
<p>
The solution with the asymptotic conditions \(m \rightarrow \mp m_0\)
as \(x \rightarrow \mp \infty\) is a scaled and shifted \(\tanh\) but
I'm struggling to prove this.
</p>

<p>
Consider that this is a solution because a step function would spike
derivatives of \(m(x)\) and raise the free energy but too gentle a
gradient means that too many points will be different from \(m_0\)
costs free energy. So we have some kind of balance.
</p>

<p>
We can compute how much this domain wall costs us in terms of free
energy by plugging the solution back in. It depends on the <i>area</i> of
the domain wall.
</p>
</div>
</li>

<li><a id="orge25b0bd"></a>Lower critical dimension<br />
<div class="outline-text-6" id="text-orge25b0bd">
<p>
Turns out that domain walls are responsible for the lack of phase
transitions in \(d=1\).
</p>

<p>
Consider \(d=1\) on some finite interval. Fix the magnetisation at the
left hand side to be \(m=m_0\). Is the preferred state \(m=m_0\)
everywhere? No.
</p>

<p>
There is always a probability that a domain wall will appear in the
thermal ensemble and push us over to the other ground state
\(m=-m_0\). The probability is given by
</p>
\begin{equation}
\label{eq:33}
p[ \text{wall at }x=X] = \frac{e^{-\beta F_{\text{wall}}}}{Z}
\end{equation}
<p>
But because the wall can occur at any point along the interval
</p>
\begin{equation}
\label{eq:34}
p[ \text{wall anywhere}] = \frac{e^{-\beta F_{\text{wall}}}}{Z} \frac{L}{W}
\end{equation}
<p>
where the extra factor will overwhelm any exponential suppression we
may have had. This is an example of entropy of a configuration
outweighting the energetic cost.
</p>

<p>
When we take into account situations with multiple domain walls we
find that there need be no coherence between a fixed \(m=m_0\) at one
end and the value somewhere else asymptotically.
</p>

<p>
However, when we go above \(d=1\), the free energy cost of the domain
wall scales with system size. Among other reasons, this means that
they don't play much of a role in \(d \geq 2\) but in \(d=2\), they
will be important close to critical points.
</p>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<!-- comment -->
<footer class="footer">
<div class="footer-left">
Created by Alex Goodenbour, 2023
</div>
<div class="footer-right">
<a id='orglink' href="https://orgmode.org/manual/Publishing.html">
<img id="emacsbadge" src="/res/made10.png">
</a>
</div>
<div style="clear:both;" />
</footer>

<!-- Hack to get around the org-mode exporter -->
<script>
    // Get the elements by their IDs
    const element1 = document.getElementById("preamble");
    const element2 = document.getElementById("content");
    const element3 = document.getElementById("postamble");

    // Create a new div element
    const wrapperDiv = document.createElement("div");
    wrapperDiv.id = 'container';
    wrapperDiv.className = 'container';

    // Append the elements to the div
    wrapperDiv.appendChild(element1);
    wrapperDiv.appendChild(element2);
    wrapperDiv.appendChild(element3);

    // Get the body element where you want to insert the wrapper div
    const body = document.body;

    // Append the wrapper div to the body
    body.appendChild(wrapperDiv);
</script>
</div>
</body>
</html>